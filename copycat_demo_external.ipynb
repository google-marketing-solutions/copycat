{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRPNTO24VHCE"
      },
      "source": [
        "# Copycat Demo\n",
        "\n",
        "This is a demo of the copycat AI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNtHvsSXDegs"
      },
      "source": [
        "## Git-on-Borg set-up\n",
        "If this is first time using GoB in this runtime; go to https://professional-services.googlesource.com/new-password and follow the steps. Eventually you should be shown a box with some bash code in it. Copy and paste the code into the cell below, replacing the text `[YOUR AUTH SCRIPT GOES HERE]`. Then run that cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYXgxuAx4mVw"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "[YOUR AUTH SCRIPT GOES HERE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egpy2CoDEHL9"
      },
      "source": [
        "## Install copcat through pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THYmZk4xENsB"
      },
      "outputs": [],
      "source": [
        "%pip install 'git+https://professional-services.googlesource.com/solutions/copycat#egg=copycat\u0026subdirectory=py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGm2-PvkzSKh"
      },
      "outputs": [],
      "source": [
        "import copycat\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.cloud import aiplatform\n",
        "from google.auth import default\n",
        "import vertexai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSihtJkzFLcR"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cK9v9WDw59i6"
      },
      "outputs": [],
      "source": [
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g6EqjwyU8Ri"
      },
      "source": [
        "# Authenticate Vertex AI and gSpread\n",
        "\n",
        "Complete\n",
        "\n",
        "1.   **_PROJECT_ID** with the GCP Project ID where you want to use VertexAI (make sure you have the vertexAI and Spreadsheets API enabled)\n",
        "2.   **_LOCATION** with the [location](https://cloud.google.com/vertex-ai/docs/general/locations#available-regions) where to run vertexAI\n",
        "\n",
        "If you run into ADC authentication errors then it might be required to re-authenticate GCP credentials in your runtime. Uncomment and run the cell below to resolve this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7NpAzO3Fe9S"
      },
      "outputs": [],
      "source": [
        "# !gcloud auth application-default login --scopes 'https://www.googleapis.com/auth/cloud-platform','https://www.googleapis.com/auth/spreadsheets','https://www.googleapis.com/auth/drive'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAs4PTXeUh0x"
      },
      "outputs": [],
      "source": [
        "auth.authenticate_user()\n",
        "\n",
        "_PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
        "_LOCATION = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "vertexai.init(project=_PROJECT_ID, location=_LOCATION)\n",
        "creds, _ = default(scopes=[\n",
        "    'https://www.googleapis.com/auth/spreadsheets',\n",
        "    'https://www.googleapis.com/auth/drive'\n",
        "]\n",
        ")\n",
        "GSPREAD_CLIENT = gspread.authorize(creds)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aieO2rTOBY8h"
      },
      "source": [
        "# Load data from google sheets\n",
        "\n",
        "First I load in the input data that has been downloaded from google ads reports.\n",
        "For this, enter the URLs and sheet names for the google sheets containing the\n",
        "data for each report. If the google sheets only have a single tab, you don't\n",
        "need to set the sheet name, it will take the first sheet by default. The linked\n",
        "sheet here is the\n",
        "[CopyCat Data Template](https://docs.google.com/spreadsheets/d/1u-Ex25XkVKFzn0r0LuxROeAtbGsOzlnmU15PzHignXw/edit?gid=0#gid=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vHX3r7fy_gE2"
      },
      "outputs": [],
      "source": [
        "def load_data_from_google_sheet(\n",
        "    url: str, worksheet_name: str, client: gspread.Client, skip_rows: int = 0\n",
        ") -\u003e pd.DataFrame:\n",
        "  \"\"\"Loads data from a Google Sheet to pandas dataframe.\"\"\"\n",
        "  input_sheet = client.open_by_url(url)\n",
        "\n",
        "  if worksheet_name:\n",
        "    values = input_sheet.worksheet(worksheet_name).get_all_values()\n",
        "  else:\n",
        "    values = input_sheet.sheet1.get_all_values()\n",
        "\n",
        "  return pd.DataFrame.from_records(\n",
        "      values[skip_rows + 1 :], columns=values[skip_rows]\n",
        "  )\n",
        "\n",
        "\n",
        "def write_data_to_google_sheet(\n",
        "    sheet_name: str, data: pd.DataFrame, client: gspread.Client\n",
        ") -\u003e gspread.Worksheet:\n",
        "  \"\"\"Writes data to a Google Sheet.\"\"\"\n",
        "  values = data.values.tolist()\n",
        "  column_names = data.columns.tolist()\n",
        "  values.insert(0, column_names)\n",
        "  worksheet = client.create(sheet_name)\n",
        "\n",
        "  column_letters = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "\n",
        "  worksheet.sheet1.update(\n",
        "      f\"A1:{column_letters[len(values[0])-1]}{len(values)+1}\", values\n",
        "  )\n",
        "  return worksheet\n",
        "\n",
        "\n",
        "ad_report_url = \"https://docs.google.com/spreadsheets/d/1u-Ex25XkVKFzn0r0LuxROeAtbGsOzlnmU15PzHignXw/edit?gid=1482290088#gid=1482290088\"  # @param {type:\"string\"}\n",
        "ad_report_sheet_name = \"existing_ads\"  # @param {type:\"string\"}\n",
        "search_keyword_report_url = \"https://docs.google.com/spreadsheets/d/1u-Ex25XkVKFzn0r0LuxROeAtbGsOzlnmU15PzHignXw/edit?gid=1482290088#gid=1482290088\"  # @param {type:\"string\"}\n",
        "search_keyword_report_sheet_name = \"existing_keywords\"  # @param {type:\"string\"}\n",
        "new_keywords_url = \"https://docs.google.com/spreadsheets/d/1u-Ex25XkVKFzn0r0LuxROeAtbGsOzlnmU15PzHignXw/edit?gid=1482290088#gid=1482290088\"  # @param {type:\"string\"}\n",
        "new_keywords_sheet_name = \"new_keywords\"  # @param {type:\"string\"}\n",
        "\n",
        "ad_report_data = load_data_from_google_sheet(\n",
        "    ad_report_url, ad_report_sheet_name, GSPREAD_CLIENT, skip_rows=0\n",
        ")\n",
        "search_keyword_report_data = load_data_from_google_sheet(\n",
        "    search_keyword_report_url,\n",
        "    search_keyword_report_sheet_name,\n",
        "    GSPREAD_CLIENT,\n",
        "    skip_rows=0,\n",
        ")\n",
        "new_keywords_data = load_data_from_google_sheet(\n",
        "    new_keywords_url, new_keywords_sheet_name, GSPREAD_CLIENT, skip_rows=0\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibavp9Y1AKFf"
      },
      "source": [
        "# Process data\n",
        "\n",
        "This combines the keywords and the ad copy together, and formats it so that it's\n",
        "ready for copycat. In the final solution this will be handled by the google\n",
        "sheet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9Nh3Kc7ImC7"
      },
      "outputs": [],
      "source": [
        "clean_ad_report_data = ad_report_data.copy()\n",
        "\n",
        "headline_cols = [\n",
        "    c\n",
        "    for c in clean_ad_report_data.columns\n",
        "    if c.startswith(\"Headline\") and not c.endswith(\"position\")\n",
        "]\n",
        "description_cols = [\n",
        "    c\n",
        "    for c in clean_ad_report_data.columns\n",
        "    if c.startswith(\"Description\") and not c.endswith(\"position\")\n",
        "]\n",
        "clean_ad_report_data[\"headlines\"] = pd.Series(\n",
        "    {\n",
        "        k: list(\n",
        "            filter(lambda x: x != \"--\" and x and not x.startswith(\"{\"), v),\n",
        "        )\n",
        "        for k, v in clean_ad_report_data[headline_cols]\n",
        "        .T.to_dict(\"list\")\n",
        "        .items()\n",
        "    },\n",
        "    index=clean_ad_report_data.index,\n",
        ")\n",
        "clean_ad_report_data[\"descriptions\"] = pd.Series(\n",
        "    {\n",
        "        k: list(filter(lambda x: x != \"--\" and x, v))\n",
        "        for k, v in clean_ad_report_data[description_cols]\n",
        "        .T.to_dict(\"list\")\n",
        "        .items()\n",
        "    },\n",
        "    index=clean_ad_report_data.index,\n",
        ")\n",
        "clean_ad_report_data = clean_ad_report_data.set_index([\"campaign\", \"ad_group\"])[\n",
        "    [\"headlines\", \"descriptions\"]\n",
        "]\n",
        "clean_ad_report_data = clean_ad_report_data.loc[\n",
        "    clean_ad_report_data[\"headlines\"].apply(len) \u003e 0\n",
        "]\n",
        "\n",
        "print(\"Unique counts: \")\n",
        "print(clean_ad_report_data[[\"headlines\", \"descriptions\"]].astype(str).nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghFp3NgdVnHA"
      },
      "outputs": [],
      "source": [
        "keywords_data = search_keyword_report_data[\n",
        "    [\"campaign\", \"ad_group\", \"keywords\"]\n",
        "].copy()\n",
        "keywords_data[\"keywords\"] = keywords_data[\"keywords\"].str.strip('[]\"')\n",
        "keywords_data = keywords_data.drop_duplicates()\n",
        "keywords_data = keywords_data.set_index([\"campaign\", \"ad_group\"])\n",
        "keywords_data = keywords_data.loc[keywords_data[\"keywords\"] != \"\"]\n",
        "\n",
        "print(f\"{keywords_data['keywords'].nunique()} unique keyword lists\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0a8kPsqNVnKG"
      },
      "outputs": [],
      "source": [
        "train_data = pd.merge(\n",
        "    keywords_data,\n",
        "    clean_ad_report_data,\n",
        "    how=\"inner\",\n",
        "    left_index=True,\n",
        "    right_index=True,\n",
        ")\n",
        "\n",
        "\n",
        "print(\n",
        "    f\"{len(train_data):,} unique combiations of keywords, headlines and\"\n",
        "    \" descriptions\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALxN0ZmrVnMt"
      },
      "outputs": [],
      "source": [
        "test_data = new_keywords_data.drop_duplicates()\n",
        "print(f\"{len(test_data):,} new lists of keywords\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KuN3ge1VnOy"
      },
      "outputs": [],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqtSD4ZUV9S6"
      },
      "outputs": [],
      "source": [
        "test_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNgUDDsIFXD7"
      },
      "source": [
        "# Copycat Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIwxoK-oFaEO"
      },
      "outputs": [],
      "source": [
        "COMPANY_NAME = \"YOUR_BRAND\"  # @param {type:\"string\"}\n",
        "USE_STYLE_GUIDE = False  # @param {type:\"boolean\"}\n",
        "EMBEDDING_MODEL_NAME = \"text-embedding-004\"  # @param {type:\"string\"}\n",
        "AD_FORMAT = \"responsive_search_ad\"  # @param {type:\"string\"}\n",
        "LANGUAGE = \"english\"  # @param {type:\"string\"}\n",
        "\n",
        "NUM_IN_CONTEXT_EXAMPLES = 5  # @param {type:\"integer\"}\n",
        "CHAT_MODEL_NAME = \"gemini-1.5-pro-preview-0514\" # @param [\"gemini-1.5-flash-preview-0514\", \"gemini-1.0-pro\", \"gemini-1.5-pro-preview-0514\"]\n",
        "TEMPERATURE = 1  # @param {type:\"slider\", min:0, max:2, step:0.01}\n",
        "TOP_K = 40  # @param {type:\"integer\"}\n",
        "TOP_P = 0.95  # @param {type:\"number\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IKMHAV8_1yo"
      },
      "source": [
        "# Style Guide Generation\n",
        "\n",
        "Copycat's distintive performance mainly comes from it's ability to leverage a\n",
        "style guide to generate the ad copies and stick close to and advertsiers style.\n",
        "\n",
        "To generate a style guide:\n",
        "\n",
        "1.  Export the training data to a google sheet (run the first cell below).\n",
        "2.  Navigate to\n",
        "    [AI Studio](https://aistudio-preprod.corp.google.com/app/prompts/new_chat)\n",
        "3.  On the top right, select `gemini 1.5 pro`.\n",
        "4.  Copy and paste the following prompt in the chat box, replace YOUR_BRAND with\n",
        "    your brand's name:\n",
        "\n",
        "*This is an Ad report for YOUR_BRAND. Use this information to write a\n",
        "comprehensive style guide for this brand's ad copies that can serve as\n",
        "instruction for another model to generate ad copies for YOUR_BRAND by only\n",
        "serving it keywords and this guide. Ensure that you capure strong phrases,\n",
        "slogans and brand names of YOUR_BRAND in the guide.*\n",
        "\n",
        "1.  Use the + right of the chat box to add the training data (from google drive)\n",
        "    and any other style or branding guides you might have.\n",
        "\n",
        "2.  Run the model and copy its response by selecting the 3 dots on the top right\n",
        "    of the response message and copy the markdown and paste it below in\n",
        "    `style_guide`\n",
        "\n",
        "3.  Feel free to make any changes to the style guide to better match your brand"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgWGg6s3WBdz"
      },
      "outputs": [],
      "source": [
        "if USE_STYLE_GUIDE:\n",
        "  style_guide_prompt = \"\"\"\n",
        "  Below is an ad report for {company_name}, containing their ads (headlines and descriptions)\n",
        "  that they use on Google Search Ads for the corresponding keywords. Headlines and descriptions are lists, and\n",
        "  Google constructs ads by combining those headlines and descriptions together into ads. Therefore the headlines and descriptions\n",
        "  should be sufficiently varied that Google is able to try lots of different combinations in order to find what works best.\n",
        "\n",
        "  Use the ad report to write a comprehensive style guide for this brand's ad copies that can serve as\n",
        "  instruction for a copywriter to write new ad copies for {company_name} for new lists of keywords.\n",
        "\n",
        "  Ensure that you capure strong phrases, slogans and brand names of {company_name} in the guide.\n",
        "  \\n\\n{style_guide}\n",
        "  \"\"\".format(\n",
        "      company_name=COMPANY_NAME,\n",
        "      style_guide=train_data.reset_index(drop=True).astype(str).to_csv(),\n",
        "  )\n",
        "\n",
        "  response = copycat.ad_copy_generator.generative_models.GenerativeModel(\n",
        "      \"gemini-1.5-pro-preview-0514\",\n",
        "      generation_config={\n",
        "          \"temperature\": 0.95,\n",
        "          \"top_k\": 20,\n",
        "          \"top_p\": 0.95,\n",
        "      },\n",
        "  ).generate_content(style_guide_prompt)\n",
        "\n",
        "  style_guide = response.candidates[0].content.parts[0].text\n",
        "\n",
        "  display(Markdown(style_guide))\n",
        "else:\n",
        "  style_guide = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQiDDYiuRe_U"
      },
      "source": [
        "# Copycat Generation\n",
        "\n",
        "First we set up the copycat model. This will process the existing ads and put\n",
        "them into a vectorstore, so they can be easily retrieved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlwkL4jORdW8"
      },
      "outputs": [],
      "source": [
        "model = copycat.Copycat.create_from_pandas(\n",
        "    training_data=train_data,\n",
        "    embedding_model_name=EMBEDDING_MODEL_NAME,\n",
        "    ad_format=AD_FORMAT,\n",
        "    on_invalid_ad=\"skip\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi1JQaGPXtnr"
      },
      "source": [
        "First lets look at how the prompt looks. Here is an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5p1bT9CXqE2"
      },
      "outputs": [],
      "source": [
        "display(Markdown(\n",
        "  model.construct_text_generation_requests_for_new_ad_copy(\n",
        "      keywords=[test_data[\"keywords\"].values[0]],\n",
        "      system_instruction_kwargs = dict(\n",
        "          company_name=COMPANY_NAME,\n",
        "          language=LANGUAGE,\n",
        "      ),\n",
        "      style_guide=style_guide,\n",
        "      num_in_context_examples=NUM_IN_CONTEXT_EXAMPLES,\n",
        "      model_name=CHAT_MODEL_NAME,\n",
        "      temperature=TEMPERATURE,\n",
        "      top_k=TOP_K,\n",
        "      top_p=TOP_P,\n",
        "  )[0].to_markdown()\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kESatqgYNpw"
      },
      "source": [
        "Now lets see a single response:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYh2fCXaYMom"
      },
      "outputs": [],
      "source": [
        "response = model.generate_new_ad_copy(\n",
        "    keywords=[test_data[\"keywords\"].values[0]],\n",
        "    keywords_specific_instructions=[\n",
        "        test_data[\"keywords_instructions\"].values[0]\n",
        "    ],\n",
        "    system_instruction_kwargs=dict(\n",
        "        company_name=COMPANY_NAME,\n",
        "        language=LANGUAGE,\n",
        "    ),\n",
        "    style_guide=style_guide,\n",
        "    num_in_context_examples=NUM_IN_CONTEXT_EXAMPLES,\n",
        "    model_name=CHAT_MODEL_NAME,\n",
        "    temperature=TEMPERATURE,\n",
        "    top_k=TOP_K,\n",
        "    top_p=TOP_P,\n",
        ")[0]\n",
        "\n",
        "display(Markdown(str(response.google_ad)))\n",
        "if not response.success:\n",
        "  print(response.error_message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxKq6h1JYiKR"
      },
      "source": [
        "If that looks good, let's generate for all the test data. You can select the\n",
        "batch size to control how many ads to generate in parallel. If the batch size is\n",
        "large then you will process the data faster, but you may hit quota limits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EjRgy6oyzO_"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 15  # @param {type:\"integer\"}\n",
        "\n",
        "generated_ads = []\n",
        "n_batches = np.ceil(len(test_data) / BATCH_SIZE)\n",
        "\n",
        "for keywords_batch in tqdm(np.array_split(test_data, n_batches), desc=\"Batch\"):\n",
        "  generated_ads.extend(\n",
        "      model.generate_new_ad_copy(\n",
        "          keywords=keywords_batch[\"keywords\"].values.tolist(),\n",
        "          keywords_specific_instructions=keywords_batch[\n",
        "              \"keywords_instructions\"\n",
        "          ].values.tolist(),\n",
        "          system_instruction_kwargs=dict(\n",
        "              company_name=COMPANY_NAME,\n",
        "              language=LANGUAGE,\n",
        "          ),\n",
        "          style_guide=style_guide,\n",
        "          num_in_context_examples=NUM_IN_CONTEXT_EXAMPLES,\n",
        "          model_name=CHAT_MODEL_NAME,\n",
        "          temperature=TEMPERATURE,\n",
        "          top_k=TOP_K,\n",
        "          top_p=TOP_P,\n",
        "      )\n",
        "  )\n",
        "  incomplete_keywords = [\n",
        "      idx\n",
        "      for idx, response in enumerate(generated_ads)\n",
        "      if len(response.google_ad.headlines) \u003c model.ad_format.max_headlines\n",
        "      or len(response.google_ad.descriptions) \u003c model.ad_format.max_descriptions\n",
        "  ]\n",
        "test_data[\"generated_ad_object\"] = pd.Series(\n",
        "    generated_ads, index=test_data.index\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maj27D2L5tMd"
      },
      "outputs": [],
      "source": [
        "def _add_existing_ad_to_instructions(\n",
        "    row: pd.Series,\n",
        "    max_headlines: int = max_headlines,\n",
        "    max_descriptions: int = 4,\n",
        ") -\u003e str:\n",
        "  instructions = row[\"keyword_instructions\"]\n",
        "  headlines = row[\"generated_ad_object\"].google_ad.headlines\n",
        "  descriptions = row[\"generated_ad_object\"].google_ad.descriptions\n",
        "\n",
        "  n_existing_headlines = len(headlines)\n",
        "  n_existing_descriptions = len(descriptions)\n",
        "  n_required_headlines = max_headlines - n_existing_headlines\n",
        "  n_required_descriptions = max_descriptions - n_existing_descriptions\n",
        "\n",
        "  if (0 \u003c n_required_headlines \u003c max_headlines) and (\n",
        "      0 \u003c n_required_descriptions \u003c max_descriptions\n",
        "  ):\n",
        "    instructions += (\n",
        "        f\"\\n\\nThis ad already has {n_existing_headlines} headlines and\"\n",
        "        f\" {n_existing_descriptions} descriptions. You only need to add\"\n",
        "        f\" {n_required_headlines} headlines and\"\n",
        "        f\" {n_required_descriptions} descriptions to complete the ad. The\"\n",
        "        \" existing headlines and descriptions are: \\n- headlines:\"\n",
        "        f\" {headlines}\\n- descriptions: {descriptions}\"\n",
        "    )\n",
        "  elif (0 \u003c n_required_headlines \u003c max_headlines) and (\n",
        "      n_required_descriptions == 0\n",
        "  ):\n",
        "    instructions += (\n",
        "        f\"\\n\\nThis ad already has {n_existing_headlines} headlines and\"\n",
        "        f\" {n_existing_descriptions} descriptions. You only need to add\"\n",
        "        f\" {n_required_headlines} headlines to complete the ad. You do not need\"\n",
        "        \" to generate any descriptions, as there are enough already. The\"\n",
        "        \" existing headlines and descriptions are: \\n- headlines:\"\n",
        "        f\" {headlines}\\n- descriptions: {descriptions}\"\n",
        "    )\n",
        "  elif (0 \u003c n_required_headlines \u003c max_headlines) and (\n",
        "      n_existing_descriptions == 0\n",
        "  ):\n",
        "    instructions += (\n",
        "        f\"\\n\\nThis ad already has {n_existing_headlines} headlines. You only\"\n",
        "        f\" need to add {n_required_headlines} headlines to complete the ad, as\"\n",
        "        f\" well as {n_required_descriptions} descriptions. The existing\"\n",
        "        f\" headlines are: \\n- headlines: {headlines}\"\n",
        "    )\n",
        "  elif (n_required_headlines == 0) and (\n",
        "      0 \u003c n_required_descriptions \u003c max_descriptions\n",
        "  ):\n",
        "    instructions += (\n",
        "        f\"\\n\\nThis ad already has {n_existing_headlines} headlines and\"\n",
        "        f\" {n_existing_descriptions} descriptions. You only need to add\"\n",
        "        f\" {n_required_descriptions} descriptions to complete the ad. You do\"\n",
        "        \" not need to generate any headlines, as there are enough already. The\"\n",
        "        \" existing headlines and descriptions are: \\n- headlines:\"\n",
        "        f\" {headlines}\\n- descriptions: {descriptions}\"\n",
        "    )\n",
        "  elif (n_required_headlines == max_headlines) and (\n",
        "      0 \u003c n_required_descriptions \u003c max_descriptions\n",
        "  ):\n",
        "    instructions += (\n",
        "        f\"\\n\\nThis ad already has {n_existing_descriptions} descriptions. You\"\n",
        "        f\" only need to add {n_required_descriptions} descriptions to complete\"\n",
        "        f\" the ad, as well as {n_required_headlines} headlines. The existing\"\n",
        "        f\" descriptions are: \\n- descriptions: {descriptions}\"\n",
        "    )\n",
        "\n",
        "  return instructions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXGBCLyX5veY"
      },
      "outputs": [],
      "source": [
        "test_data[\"is_complete\"] = test_data[\"generated_ad_object\"].apply(\n",
        "    lambda x: model.ad_copy_evaluator.is_complete(x.google_ad)\n",
        ")\n",
        "fraction_complete = test_data[\"is_complete\"].mean()\n",
        "n_retries = 0\n",
        "while fraction_complete \u003c 1.0:\n",
        "  n_retries += 1\n",
        "  print(f\"{n_retries} / 5: Fraction complete {fraction_complete:.1%}\")\n",
        "\n",
        "  incomplete_rows = test_data.loc[~test_data[\"is_complete\"]].copy()\n",
        "\n",
        "  extended_incomplete_ads = []\n",
        "\n",
        "  for keywords_batch in tqdm(\n",
        "      np.array_split(incomplete_rows, n_batches), desc=\"Batch\"\n",
        "  ):\n",
        "    extended_incomplete_ads.extend(\n",
        "        model.generate_new_ad_copy(\n",
        "            keywords=keywords_batch[\"keywords\"].values.tolist(),\n",
        "            keywords_specific_instructions=keywords_batch[\n",
        "                \"keywords_instructions\"\n",
        "            ].values.tolist(),\n",
        "            system_instruction_kwargs=dict(\n",
        "                company_name=COMPANY_NAME,\n",
        "                language=LANGUAGE,\n",
        "            ),\n",
        "            style_guide=style_guide,\n",
        "            num_in_context_examples=NUM_IN_CONTEXT_EXAMPLES,\n",
        "            model_name=CHAT_MODEL_NAME,\n",
        "            temperature=TEMPERATURE,\n",
        "            top_k=TOP_K,\n",
        "            top_p=TOP_P,\n",
        "        )\n",
        "    )\n",
        "\n",
        "  extended_incomplete_ads = pd.Series(\n",
        "      extended_incomplete_ads, index=incomplete_rows.index\n",
        "  )\n",
        "  for index, extended_incomplete_ad in extended_incomplete_ads.items():\n",
        "    test_data.loc[index, \"generated_ad_object\"].google_ad.headlines.extend(\n",
        "        extended_incomplete_ad.google_ad.headlines\n",
        "    )\n",
        "    test_data.loc[index, \"generated_ad_object\"].google_ad.descriptions.extend(\n",
        "        extended_incomplete_ad.google_ad.descriptions\n",
        "    )\n",
        "    copycat.ad_copy_generator.remove_invalid_headlines_and_descriptions(\n",
        "        test_data.loc[index, \"generated_ad_object\"].google_ad, model.ad_format\n",
        "    )\n",
        "\n",
        "  test_data[\"is_complete\"] = test_data[\"generated_ad_object\"].apply(\n",
        "      lambda x: model.ad_copy_evaluator.is_complete(x.google_ad)\n",
        "  )\n",
        "  fraction_complete = test_data[\"is_complete\"].mean()\n",
        "\n",
        "  if n_retries \u003e= 5:\n",
        "    break\n",
        "\n",
        "print(f\"Fraction complete: {fraction_complete:.1%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ifXksodhSVD"
      },
      "outputs": [],
      "source": [
        "for response in test_data[\"generated_ad_object\"].values:\n",
        "  print(\"\")\n",
        "  print(response.keywords)\n",
        "  display(Markdown(str(response.google_ad)))\n",
        "  if not response.success:\n",
        "    print(response.error_message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBijR_PMYrbN"
      },
      "source": [
        "Finally we export back to google sheets. This will be default export to the\n",
        "google sheet where the new keywords were taken from, but a different tab names\n",
        "\"Copycat generated sample\". Make sure that sheet exists otherwise this wont\n",
        "work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLcZ5rOXYo1t"
      },
      "outputs": [],
      "source": [
        "def extract_headlines(response):\n",
        "  return pd.Series(\n",
        "      response.google_ad.headlines,\n",
        "      index=[\n",
        "          f\"Headline {i+1}\" for i in range(len(response.google_ad.headlines))\n",
        "      ],\n",
        "  )\n",
        "\n",
        "\n",
        "def extract_descriptions(response):\n",
        "  return pd.Series(\n",
        "      response.google_ad.descriptions,\n",
        "      index=[\n",
        "          f\"Description {i+1}\"\n",
        "          for i in range(len(response.google_ad.descriptions))\n",
        "      ],\n",
        "  )\n",
        "\n",
        "\n",
        "headlines = (\n",
        "    test_data[\"generated_ad_object\"].apply(extract_headlines).fillna(\"--\")\n",
        ")\n",
        "descriptions = (\n",
        "    test_data[\"generated_ad_object\"].apply(extract_descriptions).fillna(\"--\")\n",
        ")\n",
        "\n",
        "results = (\n",
        "    test_data[[\"keywords\"]]\n",
        "    .copy()\n",
        "    .merge(headlines, left_index=True, right_index=True)\n",
        "    .merge(descriptions, left_index=True, right_index=True)\n",
        "    .reset_index()\n",
        ")\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OupBwivdYwng"
      },
      "outputs": [],
      "source": [
        "results_sheet_name = \"Copycat Generated Sample\"  # @param {type:\"string\"}\n",
        "\n",
        "worksheet = GSPREAD_CLIENT.open_by_url(new_keywords_url)\n",
        "\n",
        "column_letters = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "\n",
        "values = results.values.tolist()\n",
        "values.insert(0, results.columns.values.tolist())\n",
        "worksheet.worksheet(results_sheet_name).update(\n",
        "    f\"A1:{column_letters[len(values[0])-1]}{len(values)+1}\", values\n",
        ")\n",
        "\n",
        "print(f\"Treatment assignment stored in google sheet: {worksheet.url}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1D5VIaYdoTPPNDVeTyNBaohVxmi3a4ogc",
          "timestamp": 1716289128687
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
